FROM openjdk:11-slim

# Set environment variables for PySpark
ENV PYSPARK_MAJOR_PYTHON_VERSION=3
ENV SPARK_VERSION=3.4.1
ENV HADOOP_VERSION=3

# Install dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    curl \
    wget \
    libpq-dev \
    gcc \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

# Download and install Spark
RUN curl -fsSL https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz | tar -xz -C /opt/ \
    && mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

# Set environment variables for Spark and Python
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.7-src.zip:$PYTHONPATH

RUN mkdir -p /opt/spark/jars /scripts

RUN wget https://jdbc.postgresql.org/download/postgresql-42.7.2.jar -O /opt/spark/jars/postgresql-42.7.2.jar

RUN pip3 install pyspark pandas numpy scipy matplotlib scikit-learn psycopg2-binary

WORKDIR /scripts

COPY DataExtraction/process_swimming_data.py .
COPY DataExtraction/create_tables.sql .
COPY DataExtraction/raw_data/ ./raw_data/

CMD ["python3", "process_swimming_data.py"] 